{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSpeePCvGDn48t4jOdy8Cb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natanael-santosd/Final-Project-Fusemachines/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **An Example of Emotion Detection and Topic Modeling Analysis of Crime News Comments on Instagram: The Paula Santana's Case**\n",
        "#### By Natanael Santos Delgado"
      ],
      "metadata": {
        "id": "02tUZmmLNLqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I am trying to find out what are the most common reactions of the Dominican users of IG when prompted crime news. I am analyzing the case of Paula Santana, who was the victim of two co-workers (killed in her job); one of them she had reported for harassment, but Human Resources didn't take it seriously. These kind of news always cause a strong reaction from the public, so I think it should be interesting to analyze these comments and try to establish the public's position on how to adress these issues, how it affects security concerns, especially for women, and a reflection on the victim's validation: people care more about victim's that are young, students, beautiful, etc. rather than the nature of the crime.\n",
        "\n",
        "For emotion detection, I use a Support Vector Machine (SVM) classifier trained on TF-IDF vectors of comment text and for topic modeling, I use Latent Dirichlet Allocation (LDA). I also use a Multinomial Naive Bayes classifier to classify comments into sentiment categories such as positive, negative, or neutral or just how strong the negative reactions were.\n",
        "\n",
        "One of the main challenges was the data collection, because web scraping for IG web seems to be very difficult, hence, many researchers prefer to extract comments from Twitter. I decided to use APIFY's instagram scraper for small news and excel cleaning for the mainstream media news. Also, the scope of my research questions might not be answered by the applied methods."
      ],
      "metadata": {
        "id": "ZPFs39PSot5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Literature Review**\n",
        "\n",
        "## 1.1. Discourse Analysis\n",
        "\n",
        "The International Encyclopedia of Education (2023) defines **discourse analysis** as \"*the epistemological framework for investigating discourse which allows it to approach the variety of discursive genres and to describe the complexity of the discourse and of the interaction*\".\n",
        "\n",
        "Not from me: *Discourse analysis is a field of research composed of multiple heterogeneous, largely qualitative, approaches to the study of relationships between language-in-use and the social world. Researchers in the field typically view language as a form of social practice that influences the social world, and vice versa. Many contemporary varieties of discourse analysis have, explicitly or implicitly, been influenced by Michel Foucault's theories related to power, knowledge, and discourse*.\n",
        "\n",
        "However, discourse analysis has been traditionally a qualitative research approach, that aims to extract social meaning from the study of the use of the language. According to Melissa N.P. Johnson, Ethan McLean (2020)   researchers in the field typically view language as a form of social practice that influences the social world, and vice versa.\n",
        "\n",
        "https://www.sciencedirect.com/science/article/abs/pii/S0747563216305209\n",
        "\n",
        "https://www.sciencedirect.com/science/article/abs/pii/S0010945220301854\n",
        "\n",
        "https://aclanthology.org/P19-4003/\n",
        "\n",
        "\n",
        "Not mine: Discourse analysis has been a fundamental problem in the ACL community, where the focus is to develop tools to automatically model language phenomena that go beyond the individual sentences. With the ongoing neural revolution, as the methods become more effective and flexible, analysis and interpretability beyond the sentence-level\n",
        "is of particular interests for many core language processing tasks like language modeling (Ji et al., 2016) and applications such as machine translation and its evaluation (Sennrich, 2018; Laubli et al., 2018; Joty et al., 2017), text categorization (Ji and Smith, 2017), and sentiment analysis (Nejat et al., 2017). With the advent of Internet technologies, new forms of discourse are emerging (e.g., emails and discussion forums) with novel set of challenges for the computational models.\n",
        "\n",
        "## 1.2 Emotion Detection and Topic Modeling\n",
        "\n",
        "https://arxiv.org/abs/1205.4944"
      ],
      "metadata": {
        "id": "Hf47JgdSrzg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gitpython\n",
        "import gitpython as git\n",
        "git clone https://github.com/natanael-santosd/Final-Project-Fusemachines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "AGwxqo_1NJZW",
        "outputId": "74cc7dc9-1fc6-4ade-a6be-b6cc1e542cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-3-8a2cd79f35bb>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-8a2cd79f35bb>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    git clone https://github.com/natanael-santosd/Final-Project-Fusemachines\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mainstream Media Coverage\n",
        "\n",
        "**Author:** List√≠n Diario \\\n",
        "**Date:**"
      ],
      "metadata": {
        "id": "rWCZz1tHCqIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Preprocess the comment text\n",
        "# Add your preprocessing steps here (e.g., removing special characters, converting text to lowercase)\n",
        "\n",
        "# Perform sentiment analysis on each comment\n",
        "sentiment_scores = []\n",
        "for index, row in df.iterrows():\n",
        "    comment_text = row['data']  # Assuming 'data' is the column containing comment text\n",
        "    blob = TextBlob(comment_text)\n",
        "    # Specify the language as 'es' for Spanish\n",
        "    sentiment_score = blob.sentiment.polarity\n",
        "    sentiment_scores.append(sentiment_score)\n",
        "\n",
        "# Aggregate sentiment scores to get an overall sentiment score for the crime news post\n",
        "overall_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
        "\n",
        "print(\"Overall Sentiment Score:\", overall_sentiment_score)"
      ],
      "metadata": {
        "id": "wEZcUiN9Cq4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "!pip install emoji\n",
        "import emoji\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "IULKzOYUgkRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('diariolibre2.csv')\n",
        "\n",
        "# Preprocess the comment text\n",
        "# Add your preprocessing steps here (e.g., removing special characters, converting text to lowercase)\n",
        "\n",
        "# Convert emojis to text\n",
        "#def convert_emojis_to_text(text):\n",
        "    #return emoji.demojize(text)\n",
        "\n",
        "#df['data'] = df['data'].apply(convert_emojis_to_text)\n",
        "\n",
        "# Perform sentiment analysis on each comment\n",
        "sentiment_scores = []\n",
        "for index, row in df.iterrows():\n",
        "    comment_text = row['data']\n",
        "    blob = TextBlob(comment_text)\n",
        "    sentiment_score = blob.sentiment.polarity\n",
        "    sentiment_scores.append(sentiment_score)\n",
        "\n",
        "# Aggregate sentiment scores to get an overall sentiment score for the crime news post\n",
        "overall_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
        "\n",
        "print(\"Overall Sentiment Score:\", overall_sentiment_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXgVwq5haZR0",
        "outputId": "504aa91c-b947-446e-ede2-197798b112a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Sentiment Score: -0.010933333333333331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First News Article\n",
        "\n",
        "**Author:** Female, Instagram User\n",
        "\n",
        "**Date:**\n",
        "\n",
        "**Link:**\n",
        "\n",
        "**Content:** Comment\n",
        "\n",
        "**Original Language:** Spanish\n",
        "\n",
        "She was being harassed and the company labeled it as a \"bad-taste joke\" #JusticeForPaula\n",
        "\n",
        "Paula's Case brings to the table the issue of work harassment, and with it:\n",
        "\n",
        "- The absence of efficient mechanisms for prevention and monitoring of work harassment\n",
        "\n",
        "- Normalization of harassment, ignoring that is violence and it can scalate quickly\n",
        "\n",
        "- Desvalidaci√≥n de experiencia de las v√≠ctimas"
      ],
      "metadata": {
        "id": "wKoHPQ9Eyfwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "!pip install chardet\n",
        "import chardet\n",
        "with open('data_journalist.csv', 'rb') as f:\n",
        "    encoding = chardet.detect(f.read())['encoding']\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('data_journalist.csv', encoding=encoding)\n",
        "\n",
        "# Separate features (comment text) and labels (emotion categories)\n",
        "X = df['data']  # comment text\n",
        "y = df[['sad', 'anger', 'fear', 'other']]  # emotion labels\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature extraction using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Support Vector Machine (SVM) classifier for each emotion category\n",
        "svm_models = {}\n",
        "for emotion in ['sad', 'anger', 'fear', 'other']:\n",
        "    clf = SVC(kernel='linear')\n",
        "    clf.fit(X_train_tfidf, y_train[emotion])\n",
        "    svm_models[emotion] = clf\n",
        "\n",
        "# Evaluate the models\n",
        "for emotion in ['sad', 'anger', 'fear', 'other']:\n",
        "    y_pred = svm_models[emotion].predict(X_test_tfidf)\n",
        "    print(f\"Emotion: {emotion}\")\n",
        "    print(classification_report(y_test[emotion], y_pred))"
      ],
      "metadata": {
        "id": "LSuTHlPFas9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01a9764a-0ffc-47d0-c25f-e346b99a9e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Emotion: sad\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.80      0.67         5\n",
            "           1       0.50      0.25      0.33         4\n",
            "\n",
            "    accuracy                           0.56         9\n",
            "   macro avg       0.54      0.53      0.50         9\n",
            "weighted avg       0.54      0.56      0.52         9\n",
            "\n",
            "Emotion: anger\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.25      0.33         4\n",
            "           1       0.57      0.80      0.67         5\n",
            "\n",
            "    accuracy                           0.56         9\n",
            "   macro avg       0.54      0.53      0.50         9\n",
            "weighted avg       0.54      0.56      0.52         9\n",
            "\n",
            "Emotion: fear\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         9\n",
            "\n",
            "    accuracy                           1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n",
            "Emotion: other\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         9\n",
            "\n",
            "    accuracy                           1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second News Article\n",
        "\n",
        "**Author:** Female, Instagram User\n",
        "\n",
        "**Date:**\n",
        "\n",
        "**Link:**\n",
        "\n",
        "**Content:** Comment\n",
        "\n",
        "**Original Language:** Spanish"
      ],
      "metadata": {
        "id": "lw_qxvSG5qCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('data_ricardo.csv')\n",
        "\n",
        "# Separate features (comment text) and labels (emotion categories)\n",
        "X = df['data']  # comment text\n",
        "y = df[['agreement', 'life_imp','other']]  # emotion labels\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature extraction using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Support Vector Machine (SVM) classifier for each emotion category\n",
        "svm_models = {}\n",
        "for emotion in ['agreement', 'life_imp','other']:\n",
        "    clf = SVC(kernel='linear')\n",
        "    clf.fit(X_train_tfidf, y_train[emotion])\n",
        "    svm_models[emotion] = clf\n",
        "\n",
        "# Evaluate the models\n",
        "for emotion in ['agreement', 'life_imp','other']:\n",
        "    y_pred = svm_models[emotion].predict(X_test_tfidf)\n",
        "    print(f\"Emotion: {emotion}\")\n",
        "    print(classification_report(y_test[emotion], y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dPLYvi_5sdV",
        "outputId": "8f23f117-1591-45a6-8a93-ff32d4788463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion: agreement\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         2\n",
            "           1       0.86      0.86      0.86         7\n",
            "\n",
            "    accuracy                           0.78         9\n",
            "   macro avg       0.68      0.68      0.68         9\n",
            "weighted avg       0.78      0.78      0.78         9\n",
            "\n",
            "Emotion: life_imp\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93         7\n",
            "           1       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.89         9\n",
            "   macro avg       0.94      0.75      0.80         9\n",
            "weighted avg       0.90      0.89      0.87         9\n",
            "\n",
            "Emotion: other\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         9\n",
            "\n",
            "    accuracy                           1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n"
          ]
        }
      ]
    }
  ]
}